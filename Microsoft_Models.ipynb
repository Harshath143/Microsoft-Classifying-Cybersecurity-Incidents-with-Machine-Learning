{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Ignored the following versions that require a different python version: 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11\n",
      "ERROR: Could not find a version that satisfies the requirement numpy==1.27.0 (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 1.13.3, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0, 1.21.1, 1.22.0, 1.22.1, 1.22.2, 1.22.3, 1.22.4, 1.23.0, 1.23.1, 1.23.2, 1.23.3, 1.23.4, 1.23.5, 1.24.0, 1.24.1, 1.24.2, 1.24.3, 1.24.4, 1.25.0, 1.25.1, 1.25.2, 1.26.0, 1.26.1, 1.26.2, 1.26.3, 1.26.4, 2.0.0, 2.0.1, 2.0.2, 2.1.0rc1, 2.1.0, 2.1.1, 2.1.2, 2.1.3)\n",
      "ERROR: No matching distribution found for numpy==1.27.0\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.27.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipyNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\~=mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\~%mpy'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\~cipy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\~cipy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.1.3 which is incompatible.\n",
      "tensorflow-intel 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.1.3 which is incompatible.\n",
      "thinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 2.1.3 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading scipy-1.14.1-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "     --------------------------------- ------ 51.2/60.8 kB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 60.8/60.8 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting numpy<2.3,>=1.23.5 (from scipy)\n",
      "  Using cached numpy-2.1.3-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Downloading scipy-1.14.1-cp311-cp311-win_amd64.whl (44.8 MB)\n",
      "   ---------------------------------------- 0.0/44.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/44.8 MB 660.6 kB/s eta 0:01:08\n",
      "   ---------------------------------------- 0.1/44.8 MB 975.2 kB/s eta 0:00:46\n",
      "   ---------------------------------------- 0.1/44.8 MB 1.0 MB/s eta 0:00:44\n",
      "   ---------------------------------------- 0.2/44.8 MB 1.1 MB/s eta 0:00:43\n",
      "   ---------------------------------------- 0.2/44.8 MB 981.9 kB/s eta 0:00:46\n",
      "   ---------------------------------------- 0.3/44.8 MB 983.0 kB/s eta 0:00:46\n",
      "   ---------------------------------------- 0.3/44.8 MB 999.9 kB/s eta 0:00:45\n",
      "   ---------------------------------------- 0.3/44.8 MB 952.6 kB/s eta 0:00:47\n",
      "   ---------------------------------------- 0.4/44.8 MB 969.0 kB/s eta 0:00:46\n",
      "   ---------------------------------------- 0.4/44.8 MB 958.5 kB/s eta 0:00:47\n",
      "   ---------------------------------------- 0.5/44.8 MB 1.0 MB/s eta 0:00:44\n",
      "   ---------------------------------------- 0.6/44.8 MB 1.0 MB/s eta 0:00:44\n",
      "    --------------------------------------- 0.6/44.8 MB 1.0 MB/s eta 0:00:43\n",
      "    --------------------------------------- 0.7/44.8 MB 1.1 MB/s eta 0:00:42\n",
      "    --------------------------------------- 0.7/44.8 MB 1.1 MB/s eta 0:00:41\n",
      "    --------------------------------------- 0.8/44.8 MB 1.1 MB/s eta 0:00:40\n",
      "    --------------------------------------- 0.9/44.8 MB 1.1 MB/s eta 0:00:39\n",
      "    --------------------------------------- 0.9/44.8 MB 1.1 MB/s eta 0:00:39\n",
      "    --------------------------------------- 1.0/44.8 MB 1.2 MB/s eta 0:00:38\n",
      "    --------------------------------------- 1.1/44.8 MB 1.2 MB/s eta 0:00:37\n",
      "   - -------------------------------------- 1.1/44.8 MB 1.2 MB/s eta 0:00:37\n",
      "   - -------------------------------------- 1.2/44.8 MB 1.2 MB/s eta 0:00:36\n",
      "   - -------------------------------------- 1.3/44.8 MB 1.2 MB/s eta 0:00:36\n",
      "   - -------------------------------------- 1.3/44.8 MB 1.2 MB/s eta 0:00:36\n",
      "   - -------------------------------------- 1.4/44.8 MB 1.2 MB/s eta 0:00:36\n",
      "   - -------------------------------------- 1.5/44.8 MB 1.2 MB/s eta 0:00:36\n",
      "   - -------------------------------------- 1.5/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   - -------------------------------------- 1.6/44.8 MB 1.3 MB/s eta 0:00:35\n",
      "   - -------------------------------------- 1.7/44.8 MB 1.3 MB/s eta 0:00:34\n",
      "   - -------------------------------------- 1.8/44.8 MB 1.3 MB/s eta 0:00:34\n",
      "   - -------------------------------------- 1.8/44.8 MB 1.3 MB/s eta 0:00:34\n",
      "   - -------------------------------------- 1.9/44.8 MB 1.3 MB/s eta 0:00:33\n",
      "   - -------------------------------------- 2.0/44.8 MB 1.3 MB/s eta 0:00:33\n",
      "   - -------------------------------------- 2.0/44.8 MB 1.3 MB/s eta 0:00:33\n",
      "   - -------------------------------------- 2.1/44.8 MB 1.3 MB/s eta 0:00:33\n",
      "   - -------------------------------------- 2.1/44.8 MB 1.3 MB/s eta 0:00:33\n",
      "   - -------------------------------------- 2.2/44.8 MB 1.3 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 2.3/44.8 MB 1.3 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 2.3/44.8 MB 1.3 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 2.4/44.8 MB 1.3 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 2.4/44.8 MB 1.3 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 2.4/44.8 MB 1.3 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 2.5/44.8 MB 1.3 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 2.6/44.8 MB 1.3 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 2.6/44.8 MB 1.3 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 2.7/44.8 MB 1.3 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 2.7/44.8 MB 1.2 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 2.7/44.8 MB 1.2 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 2.8/44.8 MB 1.2 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 2.8/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 2.9/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 2.9/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 2.9/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 3.0/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 3.1/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 3.1/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 3.1/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 3.2/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 3.2/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 3.3/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 3.3/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 3.4/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 3.5/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 3.5/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 3.6/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 3.6/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 3.7/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 3.7/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 3.8/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 3.8/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 3.9/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 3.9/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 4.0/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 4.0/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 4.1/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 4.1/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 4.2/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 4.2/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 4.3/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 4.3/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 4.4/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 4.4/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 4.5/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 4.6/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 4.6/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 4.7/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 4.7/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 4.7/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 4.8/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 4.8/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 4.9/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 4.9/44.8 MB 1.2 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 4.9/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 5.0/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 5.0/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 5.1/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 5.1/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 5.1/44.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ---- ----------------------------------- 5.2/44.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ---- ----------------------------------- 5.2/44.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ---- ----------------------------------- 5.3/44.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ---- ----------------------------------- 5.3/44.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ---- ----------------------------------- 5.4/44.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ---- ----------------------------------- 5.4/44.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ---- ----------------------------------- 5.5/44.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ---- ----------------------------------- 5.5/44.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ---- ----------------------------------- 5.6/44.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 5.6/44.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 5.7/44.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 5.7/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 5.7/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 5.8/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 5.8/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 5.9/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 5.9/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 6.0/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 6.0/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 6.0/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 6.1/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 6.1/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 6.2/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 6.2/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 6.3/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 6.3/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 6.4/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 6.4/44.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 6.5/44.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 6.5/44.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 6.6/44.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 6.6/44.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 6.6/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 6.7/44.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 6.7/44.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 6.8/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 6.8/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 6.9/44.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 6.9/44.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 6.9/44.8 MB 1.1 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 7.0/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 7.1/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 7.1/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 7.2/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 7.3/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 7.3/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 7.3/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 7.4/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 7.5/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 7.5/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 7.6/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 7.6/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 7.6/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 7.7/44.8 MB 1.1 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 7.8/44.8 MB 1.1 MB/s eta 0:00:34\n",
      "   ------ --------------------------------- 7.8/44.8 MB 1.1 MB/s eta 0:00:34\n",
      "   ------- -------------------------------- 7.9/44.8 MB 1.1 MB/s eta 0:00:34\n",
      "   ------- -------------------------------- 7.9/44.8 MB 1.1 MB/s eta 0:00:34\n",
      "   ------- -------------------------------- 8.0/44.8 MB 1.1 MB/s eta 0:00:34\n",
      "   ------- -------------------------------- 8.1/44.8 MB 1.1 MB/s eta 0:00:34\n",
      "   ------- -------------------------------- 8.2/44.8 MB 1.1 MB/s eta 0:00:34\n",
      "   ------- -------------------------------- 8.2/44.8 MB 1.1 MB/s eta 0:00:34\n",
      "   ------- -------------------------------- 8.3/44.8 MB 1.1 MB/s eta 0:00:33\n",
      "   ------- -------------------------------- 8.4/44.8 MB 1.1 MB/s eta 0:00:33\n",
      "   ------- -------------------------------- 8.5/44.8 MB 1.1 MB/s eta 0:00:33\n",
      "   ------- -------------------------------- 8.6/44.8 MB 1.1 MB/s eta 0:00:33\n",
      "   ------- -------------------------------- 8.7/44.8 MB 1.1 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 8.8/44.8 MB 1.1 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 8.9/44.8 MB 1.1 MB/s eta 0:00:32\n",
      "   -------- ------------------------------- 9.0/44.8 MB 1.1 MB/s eta 0:00:32\n",
      "   -------- ------------------------------- 9.1/44.8 MB 1.2 MB/s eta 0:00:31\n",
      "   -------- ------------------------------- 9.2/44.8 MB 1.2 MB/s eta 0:00:31\n",
      "   -------- ------------------------------- 9.3/44.8 MB 1.2 MB/s eta 0:00:31\n",
      "   -------- ------------------------------- 9.4/44.8 MB 1.2 MB/s eta 0:00:31\n",
      "   -------- ------------------------------- 9.4/44.8 MB 1.2 MB/s eta 0:00:31\n",
      "   -------- ------------------------------- 9.5/44.8 MB 1.2 MB/s eta 0:00:31\n",
      "   -------- ------------------------------- 9.5/44.8 MB 1.2 MB/s eta 0:00:31\n",
      "   -------- ------------------------------- 9.6/44.8 MB 1.2 MB/s eta 0:00:30\n",
      "   -------- ------------------------------- 9.7/44.8 MB 1.2 MB/s eta 0:00:30\n",
      "   -------- ------------------------------- 9.7/44.8 MB 1.2 MB/s eta 0:00:30\n",
      "   -------- ------------------------------- 9.8/44.8 MB 1.2 MB/s eta 0:00:30\n",
      "   -------- ------------------------------- 9.8/44.8 MB 1.2 MB/s eta 0:00:30\n",
      "   -------- ------------------------------- 9.9/44.8 MB 1.2 MB/s eta 0:00:30\n",
      "   -------- ------------------------------- 9.9/44.8 MB 1.2 MB/s eta 0:00:30\n",
      "   -------- ------------------------------- 10.0/44.8 MB 1.2 MB/s eta 0:00:30\n",
      "   -------- ------------------------------- 10.0/44.8 MB 1.2 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 10.1/44.8 MB 1.2 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 10.1/44.8 MB 1.2 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 10.2/44.8 MB 1.2 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 10.3/44.8 MB 1.2 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 10.3/44.8 MB 1.2 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 10.3/44.8 MB 1.2 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 10.4/44.8 MB 1.2 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 10.4/44.8 MB 1.2 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 10.5/44.8 MB 1.2 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 10.5/44.8 MB 1.2 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 10.6/44.8 MB 1.2 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 10.6/44.8 MB 1.2 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 10.7/44.8 MB 1.2 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 10.8/44.8 MB 1.2 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 10.8/44.8 MB 1.2 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 10.9/44.8 MB 1.2 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 10.9/44.8 MB 1.2 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 11.0/44.8 MB 1.2 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 11.0/44.8 MB 1.2 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 11.1/44.8 MB 1.2 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 11.2/44.8 MB 1.2 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 11.2/44.8 MB 1.2 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 11.3/44.8 MB 1.2 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 11.3/44.8 MB 1.2 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 11.3/44.8 MB 1.2 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 11.4/44.8 MB 1.2 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 11.4/44.8 MB 1.2 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 11.5/44.8 MB 1.2 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 11.5/44.8 MB 1.2 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 11.6/44.8 MB 1.2 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 11.6/44.8 MB 1.2 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 11.6/44.8 MB 1.2 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 11.7/44.8 MB 1.1 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 11.7/44.8 MB 1.1 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 11.8/44.8 MB 1.1 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 11.8/44.8 MB 1.1 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 11.8/44.8 MB 1.1 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 11.9/44.8 MB 1.1 MB/s eta 0:00:30\n",
      "   ---------- ----------------------------- 11.9/44.8 MB 1.1 MB/s eta 0:00:30\n",
      "   ---------- ----------------------------- 12.0/44.8 MB 1.1 MB/s eta 0:00:30\n",
      "   ---------- ----------------------------- 12.0/44.8 MB 1.1 MB/s eta 0:00:30\n",
      "   ---------- ----------------------------- 12.1/44.8 MB 1.1 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 12.1/44.8 MB 1.1 MB/s eta 0:00:30\n",
      "   ---------- ----------------------------- 12.2/44.8 MB 1.1 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 12.2/44.8 MB 1.1 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 12.3/44.8 MB 1.1 MB/s eta 0:00:29\n",
      "   ----------- ---------------------------- 12.3/44.8 MB 1.1 MB/s eta 0:00:29\n",
      "   ----------- ---------------------------- 12.4/44.8 MB 1.1 MB/s eta 0:00:29\n",
      "   ----------- ---------------------------- 12.4/44.8 MB 1.1 MB/s eta 0:00:29\n",
      "   ----------- ---------------------------- 12.5/44.8 MB 1.1 MB/s eta 0:00:29\n",
      "   ----------- ---------------------------- 12.6/44.8 MB 1.1 MB/s eta 0:00:29\n",
      "   ----------- ---------------------------- 12.6/44.8 MB 1.1 MB/s eta 0:00:29\n",
      "   ----------- ---------------------------- 12.7/44.8 MB 1.1 MB/s eta 0:00:29\n",
      "   ----------- ---------------------------- 12.8/44.8 MB 1.1 MB/s eta 0:00:29\n",
      "   ----------- ---------------------------- 12.9/44.8 MB 1.1 MB/s eta 0:00:29\n",
      "   ----------- ---------------------------- 12.9/44.8 MB 1.1 MB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 13.0/44.8 MB 1.1 MB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 13.1/44.8 MB 1.2 MB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 13.1/44.8 MB 1.2 MB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 13.2/44.8 MB 1.2 MB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 13.3/44.8 MB 1.2 MB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 13.4/44.8 MB 1.2 MB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 13.4/44.8 MB 1.2 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 13.5/44.8 MB 1.2 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 13.5/44.8 MB 1.2 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 13.5/44.8 MB 1.2 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 13.6/44.8 MB 1.2 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 13.6/44.8 MB 1.2 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 13.7/44.8 MB 1.2 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 13.7/44.8 MB 1.2 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 13.8/44.8 MB 1.2 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 13.9/44.8 MB 1.2 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 13.9/44.8 MB 1.2 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 14.0/44.8 MB 1.2 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 14.0/44.8 MB 1.2 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 14.0/44.8 MB 1.2 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 14.1/44.8 MB 1.2 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 14.1/44.8 MB 1.2 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 14.2/44.8 MB 1.2 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 14.2/44.8 MB 1.2 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 14.3/44.8 MB 1.2 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 14.4/44.8 MB 1.2 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 14.4/44.8 MB 1.2 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 14.5/44.8 MB 1.2 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 14.5/44.8 MB 1.2 MB/s eta 0:00:27\n",
      "   ------------- -------------------------- 14.6/44.8 MB 1.2 MB/s eta 0:00:27\n",
      "   ------------- -------------------------- 14.6/44.8 MB 1.2 MB/s eta 0:00:27\n",
      "   ------------- -------------------------- 14.7/44.8 MB 1.2 MB/s eta 0:00:27\n",
      "   ------------- -------------------------- 14.7/44.8 MB 1.2 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 14.8/44.8 MB 1.2 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 14.9/44.8 MB 1.2 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 15.0/44.8 MB 1.2 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 15.1/44.8 MB 1.2 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 15.2/44.8 MB 1.2 MB/s eta 0:00:25\n",
      "   ------------- -------------------------- 15.2/44.8 MB 1.2 MB/s eta 0:00:25\n",
      "   ------------- -------------------------- 15.3/44.8 MB 1.2 MB/s eta 0:00:25\n",
      "   ------------- -------------------------- 15.4/44.8 MB 1.2 MB/s eta 0:00:25\n",
      "   ------------- -------------------------- 15.4/44.8 MB 1.2 MB/s eta 0:00:25\n",
      "   ------------- -------------------------- 15.5/44.8 MB 1.2 MB/s eta 0:00:25\n",
      "   ------------- -------------------------- 15.6/44.8 MB 1.2 MB/s eta 0:00:25\n",
      "   ------------- -------------------------- 15.6/44.8 MB 1.2 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 15.7/44.8 MB 1.2 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 15.8/44.8 MB 1.2 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 15.9/44.8 MB 1.2 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 16.0/44.8 MB 1.2 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 16.1/44.8 MB 1.3 MB/s eta 0:00:23\n",
      "   -------------- ------------------------- 16.2/44.8 MB 1.3 MB/s eta 0:00:23\n",
      "   -------------- ------------------------- 16.3/44.8 MB 1.3 MB/s eta 0:00:23\n",
      "   -------------- ------------------------- 16.4/44.8 MB 1.3 MB/s eta 0:00:23\n",
      "   -------------- ------------------------- 16.5/44.8 MB 1.3 MB/s eta 0:00:22\n",
      "   -------------- ------------------------- 16.6/44.8 MB 1.3 MB/s eta 0:00:22\n",
      "   -------------- ------------------------- 16.6/44.8 MB 1.3 MB/s eta 0:00:22\n",
      "   -------------- ------------------------- 16.7/44.8 MB 1.3 MB/s eta 0:00:22\n",
      "   -------------- ------------------------- 16.7/44.8 MB 1.3 MB/s eta 0:00:22\n",
      "   --------------- ------------------------ 16.8/44.8 MB 1.3 MB/s eta 0:00:22\n",
      "   --------------- ------------------------ 16.9/44.8 MB 1.3 MB/s eta 0:00:22\n",
      "   --------------- ------------------------ 17.0/44.8 MB 1.3 MB/s eta 0:00:22\n",
      "   --------------- ------------------------ 17.0/44.8 MB 1.3 MB/s eta 0:00:22\n",
      "   --------------- ------------------------ 17.1/44.8 MB 1.3 MB/s eta 0:00:21\n",
      "   --------------- ------------------------ 17.2/44.8 MB 1.3 MB/s eta 0:00:21\n",
      "   --------------- ------------------------ 17.3/44.8 MB 1.3 MB/s eta 0:00:21\n",
      "   --------------- ------------------------ 17.4/44.8 MB 1.3 MB/s eta 0:00:21\n",
      "   --------------- ------------------------ 17.5/44.8 MB 1.4 MB/s eta 0:00:21\n",
      "   --------------- ------------------------ 17.7/44.8 MB 1.4 MB/s eta 0:00:20\n",
      "   --------------- ------------------------ 17.8/44.8 MB 1.4 MB/s eta 0:00:20\n",
      "   --------------- ------------------------ 17.9/44.8 MB 1.4 MB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 18.0/44.8 MB 1.4 MB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 18.1/44.8 MB 1.4 MB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 18.1/44.8 MB 1.4 MB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 18.2/44.8 MB 1.4 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 18.3/44.8 MB 1.4 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 18.3/44.8 MB 1.4 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 18.4/44.8 MB 1.4 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 18.4/44.8 MB 1.4 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 18.5/44.8 MB 1.4 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 18.6/44.8 MB 1.4 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 18.7/44.8 MB 1.4 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 18.7/44.8 MB 1.4 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 18.8/44.8 MB 1.4 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 19.0/44.8 MB 1.4 MB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 19.1/44.8 MB 1.4 MB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 19.2/44.8 MB 1.4 MB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 19.3/44.8 MB 1.4 MB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 19.4/44.8 MB 1.4 MB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 19.4/44.8 MB 1.4 MB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 19.5/44.8 MB 1.4 MB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 19.5/44.8 MB 1.4 MB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 19.6/44.8 MB 1.4 MB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 19.7/44.8 MB 1.4 MB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 19.8/44.8 MB 1.4 MB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 19.8/44.8 MB 1.4 MB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 19.9/44.8 MB 1.4 MB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 19.9/44.8 MB 1.4 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 20.0/44.8 MB 1.4 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 20.0/44.8 MB 1.4 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 20.1/44.8 MB 1.4 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 20.2/44.8 MB 1.4 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 20.2/44.8 MB 1.4 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 20.3/44.8 MB 1.4 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 20.4/44.8 MB 1.4 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 20.5/44.8 MB 1.4 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 20.6/44.8 MB 1.4 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 20.7/44.8 MB 1.4 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 20.7/44.8 MB 1.4 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 20.8/44.8 MB 1.4 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 20.9/44.8 MB 1.4 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 21.0/44.8 MB 1.4 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 21.0/44.8 MB 1.4 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 21.1/44.8 MB 1.4 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 21.2/44.8 MB 1.4 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 21.2/44.8 MB 1.4 MB/s eta 0:00:17\n",
      "   ------------------- -------------------- 21.3/44.8 MB 1.5 MB/s eta 0:00:17\n",
      "   ------------------- -------------------- 21.4/44.8 MB 1.5 MB/s eta 0:00:17\n",
      "   ------------------- -------------------- 21.5/44.8 MB 1.5 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 21.6/44.8 MB 1.5 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 21.7/44.8 MB 1.5 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 21.8/44.8 MB 1.5 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 21.9/44.8 MB 1.5 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 22.0/44.8 MB 1.5 MB/s eta 0:00:15\n",
      "   ------------------- -------------------- 22.1/44.8 MB 1.5 MB/s eta 0:00:15\n",
      "   ------------------- -------------------- 22.2/44.8 MB 1.6 MB/s eta 0:00:15\n",
      "   ------------------- -------------------- 22.3/44.8 MB 1.6 MB/s eta 0:00:15\n",
      "   -------------------- ------------------- 22.4/44.8 MB 1.6 MB/s eta 0:00:15\n",
      "   -------------------- ------------------- 22.5/44.8 MB 1.6 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 22.6/44.8 MB 1.6 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 22.7/44.8 MB 1.6 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 22.8/44.8 MB 1.6 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 23.0/44.8 MB 1.6 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 23.1/44.8 MB 1.6 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 23.2/44.8 MB 1.6 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 23.2/44.8 MB 1.6 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 23.3/44.8 MB 1.7 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 23.4/44.8 MB 1.7 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 23.5/44.8 MB 1.7 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 23.6/44.8 MB 1.7 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 23.7/44.8 MB 1.7 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 23.8/44.8 MB 1.7 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 23.9/44.8 MB 1.7 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 24.0/44.8 MB 1.7 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 24.1/44.8 MB 1.7 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 24.2/44.8 MB 1.7 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 24.2/44.8 MB 1.7 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 24.4/44.8 MB 1.8 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 24.4/44.8 MB 1.8 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 24.5/44.8 MB 1.8 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 24.6/44.8 MB 1.8 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 24.6/44.8 MB 1.8 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 24.7/44.8 MB 1.8 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 24.8/44.8 MB 1.8 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 24.9/44.8 MB 1.8 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 25.0/44.8 MB 1.8 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 25.0/44.8 MB 1.8 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 25.1/44.8 MB 1.8 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 25.2/44.8 MB 1.8 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 25.2/44.8 MB 1.8 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 25.3/44.8 MB 1.8 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 25.3/44.8 MB 1.8 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 25.4/44.8 MB 1.8 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 25.4/44.8 MB 1.8 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 25.5/44.8 MB 1.8 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 25.5/44.8 MB 1.8 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 25.6/44.8 MB 1.8 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 25.7/44.8 MB 1.8 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 25.7/44.8 MB 1.8 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 25.8/44.8 MB 1.8 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 25.8/44.8 MB 1.8 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 25.9/44.8 MB 1.8 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 26.0/44.8 MB 1.8 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 26.1/44.8 MB 1.8 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 26.1/44.8 MB 1.7 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 26.2/44.8 MB 1.8 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 26.3/44.8 MB 1.7 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 26.4/44.8 MB 1.7 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 26.4/44.8 MB 1.7 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 26.5/44.8 MB 1.7 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 26.6/44.8 MB 1.7 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 26.6/44.8 MB 1.7 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 26.7/44.8 MB 1.7 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 26.8/44.8 MB 1.7 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 26.8/44.8 MB 1.7 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 26.9/44.8 MB 1.7 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 26.9/44.8 MB 1.7 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 27.0/44.8 MB 1.7 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 27.0/44.8 MB 1.7 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 27.1/44.8 MB 1.7 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 27.1/44.8 MB 1.7 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 27.2/44.8 MB 1.7 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 27.2/44.8 MB 1.7 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 27.3/44.8 MB 1.7 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 27.3/44.8 MB 1.7 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 27.4/44.8 MB 1.7 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 27.5/44.8 MB 1.7 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 27.5/44.8 MB 1.7 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 27.6/44.8 MB 1.7 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 27.6/44.8 MB 1.7 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 27.7/44.8 MB 1.7 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 27.7/44.8 MB 1.6 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 27.8/44.8 MB 1.6 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 27.8/44.8 MB 1.6 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 27.9/44.8 MB 1.6 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 28.0/44.8 MB 1.6 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 28.0/44.8 MB 1.6 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 28.1/44.8 MB 1.6 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 28.1/44.8 MB 1.6 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 28.2/44.8 MB 1.6 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 28.2/44.8 MB 1.6 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 28.3/44.8 MB 1.6 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 28.4/44.8 MB 1.6 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 28.4/44.8 MB 1.6 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 28.5/44.8 MB 1.6 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 28.6/44.8 MB 1.6 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 28.6/44.8 MB 1.6 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 28.7/44.8 MB 1.6 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 28.7/44.8 MB 1.6 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 28.8/44.8 MB 1.6 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 28.8/44.8 MB 1.6 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 28.9/44.8 MB 1.6 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 28.9/44.8 MB 1.6 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 29.0/44.8 MB 1.6 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 29.1/44.8 MB 1.6 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 29.1/44.8 MB 1.6 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 29.2/44.8 MB 1.6 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 29.2/44.8 MB 1.5 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 29.3/44.8 MB 1.5 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 29.3/44.8 MB 1.5 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 29.4/44.8 MB 1.5 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 29.5/44.8 MB 1.5 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 29.5/44.8 MB 1.5 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 29.6/44.8 MB 1.5 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 29.6/44.8 MB 1.5 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 29.7/44.8 MB 1.5 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 29.8/44.8 MB 1.5 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 29.9/44.8 MB 1.5 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 30.0/44.8 MB 1.5 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 30.0/44.8 MB 1.5 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 30.1/44.8 MB 1.5 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 30.2/44.8 MB 1.5 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 30.3/44.8 MB 1.5 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 30.4/44.8 MB 1.6 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 30.5/44.8 MB 1.6 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 30.6/44.8 MB 1.6 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 30.7/44.8 MB 1.6 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 30.8/44.8 MB 1.6 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 30.9/44.8 MB 1.6 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 31.0/44.8 MB 1.6 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 31.0/44.8 MB 1.6 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 31.1/44.8 MB 1.6 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 31.2/44.8 MB 1.6 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 31.2/44.8 MB 1.6 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 31.2/44.8 MB 1.6 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 31.3/44.8 MB 1.6 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 31.4/44.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 31.4/44.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 31.5/44.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 31.6/44.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 31.6/44.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 31.7/44.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 31.7/44.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 31.8/44.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 31.9/44.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 31.9/44.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 32.0/44.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 32.1/44.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 32.1/44.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 32.2/44.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 32.3/44.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 32.3/44.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 32.4/44.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 32.4/44.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 32.5/44.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 32.6/44.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 32.6/44.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 32.7/44.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 32.7/44.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 32.8/44.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 32.8/44.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 32.9/44.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 33.0/44.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 33.1/44.8 MB 1.5 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 33.1/44.8 MB 1.4 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 33.2/44.8 MB 1.4 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 33.2/44.8 MB 1.4 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 33.3/44.8 MB 1.4 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 33.4/44.8 MB 1.4 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 33.4/44.8 MB 1.4 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 33.5/44.8 MB 1.4 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 33.6/44.8 MB 1.4 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 33.6/44.8 MB 1.4 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 33.7/44.8 MB 1.4 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 33.8/44.8 MB 1.4 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 33.9/44.8 MB 1.4 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 34.0/44.8 MB 1.4 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 34.1/44.8 MB 1.4 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 34.2/44.8 MB 1.4 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 34.3/44.8 MB 1.4 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 34.3/44.8 MB 1.4 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 34.4/44.8 MB 1.4 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 34.5/44.8 MB 1.4 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 34.6/44.8 MB 1.4 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 34.6/44.8 MB 1.4 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 34.7/44.8 MB 1.4 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 34.8/44.8 MB 1.4 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 34.8/44.8 MB 1.4 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 34.9/44.8 MB 1.4 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 35.0/44.8 MB 1.4 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 35.1/44.8 MB 1.4 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 35.1/44.8 MB 1.4 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 35.2/44.8 MB 1.4 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 35.3/44.8 MB 1.4 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 35.3/44.8 MB 1.4 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 35.4/44.8 MB 1.4 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 35.5/44.8 MB 1.4 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 35.5/44.8 MB 1.4 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 35.6/44.8 MB 1.4 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 35.6/44.8 MB 1.4 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 35.7/44.8 MB 1.4 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 35.8/44.8 MB 1.4 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 35.8/44.8 MB 1.4 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 35.9/44.8 MB 1.4 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 35.9/44.8 MB 1.4 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 36.0/44.8 MB 1.4 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 36.0/44.8 MB 1.4 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 36.1/44.8 MB 1.4 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 36.1/44.8 MB 1.4 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 36.2/44.8 MB 1.4 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 36.3/44.8 MB 1.4 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 36.3/44.8 MB 1.4 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 36.4/44.8 MB 1.4 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 36.4/44.8 MB 1.4 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 36.5/44.8 MB 1.4 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 36.5/44.8 MB 1.4 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 36.6/44.8 MB 1.4 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 36.7/44.8 MB 1.4 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 36.7/44.8 MB 1.4 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 36.8/44.8 MB 1.4 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 36.8/44.8 MB 1.4 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 36.9/44.8 MB 1.4 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 37.0/44.8 MB 1.4 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 37.0/44.8 MB 1.4 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 37.1/44.8 MB 1.4 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 37.1/44.8 MB 1.4 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 37.2/44.8 MB 1.4 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 37.2/44.8 MB 1.4 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 37.3/44.8 MB 1.4 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 37.4/44.8 MB 1.4 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 37.4/44.8 MB 1.4 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 37.5/44.8 MB 1.4 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 37.6/44.8 MB 1.4 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 37.6/44.8 MB 1.4 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 37.7/44.8 MB 1.4 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 37.7/44.8 MB 1.4 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 37.8/44.8 MB 1.4 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 37.9/44.8 MB 1.4 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 38.0/44.8 MB 1.4 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 38.0/44.8 MB 1.4 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 38.1/44.8 MB 1.4 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 38.2/44.8 MB 1.4 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 38.2/44.8 MB 1.4 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 38.3/44.8 MB 1.4 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 38.4/44.8 MB 1.4 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 38.4/44.8 MB 1.4 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 38.5/44.8 MB 1.4 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 38.5/44.8 MB 1.4 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 38.6/44.8 MB 1.4 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 38.6/44.8 MB 1.4 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 38.7/44.8 MB 1.4 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 38.8/44.8 MB 1.4 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 38.9/44.8 MB 1.4 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 38.9/44.8 MB 1.4 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 39.0/44.8 MB 1.4 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 39.1/44.8 MB 1.4 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 39.1/44.8 MB 1.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 39.2/44.8 MB 1.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 39.3/44.8 MB 1.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 39.4/44.8 MB 1.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 39.5/44.8 MB 1.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 39.5/44.8 MB 1.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 39.6/44.8 MB 1.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 39.7/44.8 MB 1.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 39.7/44.8 MB 1.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 39.8/44.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 39.9/44.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 39.9/44.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 40.0/44.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 40.1/44.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 40.2/44.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 40.2/44.8 MB 1.5 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 40.3/44.8 MB 1.4 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 40.4/44.8 MB 1.4 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 40.4/44.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 40.5/44.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 40.6/44.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 40.7/44.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 40.7/44.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 40.8/44.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 40.9/44.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 40.9/44.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 41.0/44.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 41.1/44.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 41.1/44.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 41.2/44.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 41.3/44.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 41.4/44.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 41.4/44.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 41.5/44.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 41.5/44.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 41.6/44.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 41.6/44.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 41.7/44.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 41.8/44.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 41.8/44.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 41.9/44.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 41.9/44.8 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 42.0/44.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 42.0/44.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 42.1/44.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 42.1/44.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 42.1/44.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 42.2/44.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 42.3/44.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 42.3/44.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 42.3/44.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 42.4/44.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 42.5/44.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 42.5/44.8 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 42.6/44.8 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 42.7/44.8 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 42.8/44.8 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 42.8/44.8 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 42.9/44.8 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 42.9/44.8 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 43.0/44.8 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 43.1/44.8 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 43.2/44.8 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 43.2/44.8 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 43.3/44.8 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 43.4/44.8 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 43.4/44.8 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 43.5/44.8 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 43.5/44.8 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 43.6/44.8 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 43.6/44.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.7/44.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.7/44.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.8/44.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.8/44.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.9/44.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.9/44.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.0/44.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.0/44.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.2/44.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.2/44.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.3/44.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.3/44.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.4/44.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.5/44.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.6/44.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.6/44.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.7/44.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.7/44.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.8/44.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.8/44.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.8/44.8 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.8/44.8 MB 1.3 MB/s eta 0:00:00\n",
      "Using cached numpy-2.1.3-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "Installing collected packages: numpy, scipy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.3\n",
      "    Uninstalling numpy-2.1.3:\n",
      "      Successfully uninstalled numpy-2.1.3\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.11.2\n",
      "    Uninstalling scipy-1.11.2:\n",
      "      Successfully uninstalled scipy-1.11.2\n",
      "Successfully installed numpy-2.1.3 scipy-1.14.1\n"
     ]
    }
   ],
   "source": [
    "pip install --force-reinstall scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dask\n",
      "  Using cached dask-2024.10.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting click>=8.1 (from dask)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting cloudpickle>=3.0.0 (from dask)\n",
      "  Using cached cloudpickle-3.1.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting fsspec>=2021.09.0 (from dask)\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting packaging>=20.0 (from dask)\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting partd>=1.4.0 (from dask)\n",
      "  Using cached partd-1.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting pyyaml>=5.3.1 (from dask)\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting toolz>=0.10.0 (from dask)\n",
      "  Using cached toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting importlib-metadata>=4.13.0 (from dask)\n",
      "  Using cached importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting colorama (from click>=8.1->dask)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata>=4.13.0->dask)\n",
      "  Using cached zipp-3.20.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting locket (from partd>=1.4.0->dask)\n",
      "  Using cached locket-1.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Using cached dask-2024.10.0-py3-none-any.whl (1.3 MB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "   ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "   ------------------------- -------------- 61.4/97.9 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 97.9/97.9 kB 1.4 MB/s eta 0:00:00\n",
      "Using cached cloudpickle-3.1.0-py3-none-any.whl (22 kB)\n",
      "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "   ---------------------------------------- 0.0/179.6 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 71.7/179.6 kB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 174.1/179.6 kB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 179.6/179.6 kB 2.2 MB/s eta 0:00:00\n",
      "Using cached importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
      "Downloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "   ---------------------------------------- 0.0/54.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 54.0/54.0 kB 2.7 MB/s eta 0:00:00\n",
      "Using cached partd-1.4.2-py3-none-any.whl (18 kB)\n",
      "Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "   ---------------------------------------- 0.0/162.0 kB ? eta -:--:--\n",
      "   -------------------- ------------------- 81.9/162.0 kB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 162.0/162.0 kB 1.9 MB/s eta 0:00:00\n",
      "Using cached toolz-1.0.0-py3-none-any.whl (56 kB)\n",
      "Using cached zipp-3.20.2-py3-none-any.whl (9.2 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Using cached locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: zipp, toolz, pyyaml, packaging, locket, fsspec, colorama, cloudpickle, partd, importlib-metadata, click, dask\n",
      "  Attempting uninstall: zipp\n",
      "    Found existing installation: zipp 3.20.2\n",
      "    Uninstalling zipp-3.20.2:\n",
      "      Successfully uninstalled zipp-3.20.2\n",
      "  Attempting uninstall: toolz\n",
      "    Found existing installation: toolz 1.0.0\n",
      "    Uninstalling toolz-1.0.0:\n",
      "      Successfully uninstalled toolz-1.0.0\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.0\n",
      "    Uninstalling packaging-23.0:\n",
      "      Successfully uninstalled packaging-23.0\n",
      "  Attempting uninstall: locket\n",
      "    Found existing installation: locket 1.0.0\n",
      "    Uninstalling locket-1.0.0:\n",
      "      Successfully uninstalled locket-1.0.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.9.0\n",
      "    Uninstalling fsspec-2024.9.0:\n",
      "      Successfully uninstalled fsspec-2024.9.0\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.6\n",
      "    Uninstalling colorama-0.4.6:\n",
      "      Successfully uninstalled colorama-0.4.6\n",
      "  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 3.1.0\n",
      "    Uninstalling cloudpickle-3.1.0:\n",
      "      Successfully uninstalled cloudpickle-3.1.0\n",
      "  Attempting uninstall: partd\n",
      "    Found existing installation: partd 1.4.2\n",
      "    Uninstalling partd-1.4.2:\n",
      "      Successfully uninstalled partd-1.4.2\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib_metadata 8.5.0\n",
      "    Uninstalling importlib_metadata-8.5.0:\n",
      "      Successfully uninstalled importlib_metadata-8.5.0\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.1.3\n",
      "    Uninstalling click-8.1.3:\n",
      "      Successfully uninstalled click-8.1.3\n",
      "  Attempting uninstall: dask\n",
      "    Found existing installation: dask 2024.10.0\n",
      "    Uninstalling dask-2024.10.0:\n",
      "      Successfully uninstalled dask-2024.10.0\n",
      "Successfully installed click-8.1.7 cloudpickle-3.1.0 colorama-0.4.6 dask-2024.10.0 fsspec-2024.10.0 importlib-metadata-8.5.0 locket-1.0.0 packaging-24.1 partd-1.4.2 pyyaml-6.0.2 toolz-1.0.0 zipp-3.20.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\~aml'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.1.3 which is incompatible.\n",
      "thinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 2.1.3 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --force-reinstall dask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning hyperparameters for Logistic Regression (SGD)...\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best Parameters for Logistic Regression (SGD): {'alpha': np.float64(0.0016599452033620266)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "c:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Logistic Regression (SGD):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.79      0.68    822191\n",
      "           1       0.60      0.19      0.29    405897\n",
      "           2       0.65      0.66      0.65    665284\n",
      "           3       0.70      0.31      0.43     10202\n",
      "\n",
      "    accuracy                           0.61   1903574\n",
      "   macro avg       0.63      0.49      0.51   1903574\n",
      "weighted avg       0.61      0.61      0.58   1903574\n",
      "\n",
      "Confusion Matrix:\n",
      "[[647222  32961 141291    717]\n",
      " [230862  78782  95686    567]\n",
      " [210720  18541 435927     96]\n",
      " [  3967   1470   1584   3181]]\n",
      "\n",
      "Tuning hyperparameters for Decision Tree...\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best Parameters for Decision Tree: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 3, 'min_samples_split': 6}\n",
      "\n",
      "Classification Report for Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    822191\n",
      "           1       0.99      0.99      0.99    405897\n",
      "           2       0.99      0.99      0.99    665284\n",
      "           3       0.97      0.96      0.97     10202\n",
      "\n",
      "    accuracy                           0.99   1903574\n",
      "   macro avg       0.99      0.98      0.99   1903574\n",
      "weighted avg       0.99      0.99      0.99   1903574\n",
      "\n",
      "Confusion Matrix:\n",
      "[[817300   2714   2054    123]\n",
      " [  3236 400723   1857     81]\n",
      " [  2760   2486 659957     81]\n",
      " [   158    100    104   9840]]\n",
      "\n",
      "Tuning hyperparameters for Random Forest...\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best Parameters for Random Forest: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 13, 'n_estimators': 100}\n",
      "\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98    822191\n",
      "           1       0.98      0.96      0.97    405897\n",
      "           2       0.99      0.98      0.98    665284\n",
      "           3       0.99      0.97      0.98     10202\n",
      "\n",
      "    accuracy                           0.98   1903574\n",
      "   macro avg       0.98      0.97      0.98   1903574\n",
      "weighted avg       0.98      0.98      0.98   1903574\n",
      "\n",
      "Confusion Matrix:\n",
      "[[813446   4945   3755     45]\n",
      " [ 12752 389095   4011     39]\n",
      " [ 12062   4402 648786     34]\n",
      " [   201     29     48   9924]]\n",
      "\n",
      "Tuning hyperparameters for HistGradientBoosting...\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best Parameters for HistGradientBoosting: {'learning_rate': np.float64(0.07011150117432088), 'max_depth': None}\n",
      "\n",
      "Classification Report for HistGradientBoosting:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90    822191\n",
      "           1       0.93      0.78      0.85    405897\n",
      "           2       0.94      0.87      0.90    665284\n",
      "           3       0.93      0.94      0.93     10202\n",
      "\n",
      "    accuracy                           0.89   1903574\n",
      "   macro avg       0.91      0.89      0.89   1903574\n",
      "weighted avg       0.89      0.89      0.89   1903574\n",
      "\n",
      "Confusion Matrix:\n",
      "[[787925  13517  20442    307]\n",
      " [ 71200 315854  18633    210]\n",
      " [ 78620   9199 577287    178]\n",
      " [   499     90     66   9547]]\n",
      "\n",
      "Tuning hyperparameters for XGBoost...\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [13:50:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for XGBoost: {'learning_rate': np.float64(0.09324426408004217), 'max_depth': 6, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [13:51:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.97      0.87    822191\n",
      "           1       0.93      0.70      0.80    405897\n",
      "           2       0.94      0.82      0.87    665284\n",
      "           3       0.92      0.88      0.90     10202\n",
      "\n",
      "    accuracy                           0.86   1903574\n",
      "   macro avg       0.89      0.84      0.86   1903574\n",
      "weighted avg       0.87      0.86      0.86   1903574\n",
      "\n",
      "Confusion Matrix:\n",
      "[[793900  12774  15208    309]\n",
      " [100261 285050  20333    253]\n",
      " [113393   8890 542809    192]\n",
      " [  1070     72     81   8979]]\n",
      "\n",
      "Best Model: Decision Tree with accuracy: 0.9526\n",
      "Best model saved as 'best_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import randint, uniform\n",
    "from dask_ml.model_selection import train_test_split as dask_train_test_split\n",
    "\n",
    "# Load large dataset using Dask\n",
    "df = dd.read_csv(r\"C:\\Projects\\Microsoft-project\\Final_Train_DS.csv\")\n",
    "\n",
    "# Check if the dataset contains missing values\n",
    "missing_values = df.isnull().sum().compute()  # Compute the missing values count\n",
    "if missing_values.any():\n",
    "    print(\"Warning: Dataset contains missing values. Consider handling them before proceeding.\")\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop('IncidentGrade', axis=1)\n",
    "y = df['IncidentGrade']\n",
    "\n",
    "# Split data into training and test sets (use Dask for memory efficiency)\n",
    "X_train, X_test, y_train, y_test = dask_train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Convert Dask DataFrames to smaller sample NumPy arrays for hyperparameter tuning\n",
    "X_train_sample = X_train.sample(frac=0.1, random_state=42).compute().reset_index(drop=True)\n",
    "y_train_sample = y_train.sample(frac=0.1, random_state=42).compute().reset_index(drop=True)\n",
    "\n",
    "# Standardize features for sample data\n",
    "scaler = StandardScaler()\n",
    "X_train_sample_scaled = scaler.fit_transform(X_train_sample)\n",
    "\n",
    "# Models and parameter grids\n",
    "models = {\n",
    "    \"Logistic Regression (SGD)\": (SGDClassifier(loss='log_loss', max_iter=1000, random_state=42),\n",
    "                                  {'alpha': uniform(0.0001, 0.01)}),\n",
    "\n",
    "    \"Decision Tree\": (DecisionTreeClassifier(random_state=42),\n",
    "                      {'max_depth': [5, 10, 20, None], 'min_samples_split': randint(2, 20),\n",
    "                       'min_samples_leaf': randint(1, 20), 'criterion': ['gini', 'entropy']}),\n",
    "\n",
    "    \"Random Forest\": (RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "                      {'n_estimators': [50, 100], 'max_depth': [10, 20, None],\n",
    "                       'min_samples_split': randint(2, 20), 'min_samples_leaf': randint(1, 20)}),\n",
    "\n",
    "    \"HistGradientBoosting\": (HistGradientBoostingClassifier(random_state=42, max_iter=100),\n",
    "                             {'learning_rate': uniform(0.01, 0.1), 'max_depth': [3, 6, None]}),\n",
    "\n",
    "    \"XGBoost\": (XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42, tree_method='hist'),\n",
    "                {'n_estimators': [50, 100], 'max_depth': [3, 6], 'learning_rate': uniform(0.01, 0.1)})\n",
    "}\n",
    "\n",
    "# Dictionary to store best models and scores\n",
    "best_models = {}\n",
    "best_score = 0\n",
    "best_model_name = None\n",
    "\n",
    "# Hyperparameter tuning with RandomizedSearchCV on sampled data\n",
    "for model_name, (model, param_grid) in models.items():\n",
    "    print(f\"\\nTuning hyperparameters for {model_name}...\")\n",
    "\n",
    "    random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=10, scoring='accuracy', cv=3,\n",
    "                                       random_state=42, n_jobs=-1, verbose=1)\n",
    "    random_search.fit(X_train_sample_scaled, y_train_sample)\n",
    "    \n",
    "    # Save the best model from RandomizedSearchCV\n",
    "    best_models[model_name] = random_search.best_estimator_\n",
    "    print(f\"Best Parameters for {model_name}: {random_search.best_params_}\")\n",
    "\n",
    "    # Fit best model on the full dataset if it supports incremental learning\n",
    "    if model_name == \"Logistic Regression (SGD)\":\n",
    "        # SGDClassifier: Train incrementally on chunks of data\n",
    "        X_train_computed = X_train.compute()  # Ensure the Dask DataFrame is computed to a NumPy array\n",
    "        y_train_computed = y_train.compute()  # Ensure the Dask Series is computed to a NumPy array\n",
    "        for X_batch, y_batch in zip(np.array_split(X_train_computed, 10), np.array_split(y_train_computed, 10)):\n",
    "            X_batch_scaled = scaler.transform(X_batch)\n",
    "            best_models[model_name].partial_fit(X_batch_scaled, y_batch, classes=np.unique(y_train_sample))\n",
    "    else:\n",
    "        # Train the model on full training data\n",
    "        X_train_scaled = scaler.transform(X_train.compute())\n",
    "        best_models[model_name].fit(X_train_scaled, y_train.compute())\n",
    "\n",
    "    # Predict and evaluate on test data\n",
    "    X_test_scaled = scaler.transform(X_test.compute())\n",
    "    y_pred = best_models[model_name].predict(X_test_scaled)\n",
    "\n",
    "    # Display classification report and confusion matrix\n",
    "    print(f\"\\nClassification Report for {model_name}:\")\n",
    "    print(classification_report(y_test.compute(), y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test.compute(), y_pred))\n",
    "\n",
    "    # Update the best model based on test score\n",
    "    test_score = random_search.best_score_\n",
    "    if test_score > best_score:\n",
    "        best_score = test_score\n",
    "        best_model_name = model_name\n",
    "\n",
    "# Save the best model to a .pkl file\n",
    "best_model = best_models[best_model_name]\n",
    "print(f\"\\nBest Model: {best_model_name} with accuracy: {best_score:.4f}\")\n",
    "with open(\"best_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_model, f)\n",
    "print(\"Best model saved as 'best_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model saved as 'random_forest_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming `best_models` dictionary has already been populated with the tuned models\n",
    "random_forest_model = best_models[\"Random Forest\"]\n",
    "\n",
    "# Save the Random Forest model to a .pkl file\n",
    "with open(\"random_forest_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(random_forest_model, f)\n",
    "\n",
    "print(\"Random Forest model saved as 'random_forest_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Table:\n",
      "               Model  Accuracy  Macro-F1 Score  Precision  Recall\n",
      " Logistic Regression      0.61            0.51       0.63    0.49\n",
      "       Decision Tree      0.99            0.99       0.98    0.99\n",
      "       Random Forest      0.98            0.98       0.98    0.97\n",
      "HistGradientBoosting      0.89            0.89       0.91    0.89\n",
      "             XGBoost      0.86            0.86       0.89    0.84\n",
      "\n",
      "Best Model Based on Macro-F1 Score:\n",
      "Model             Decision Tree\n",
      "Accuracy                   0.99\n",
      "Macro-F1 Score             0.99\n",
      "Precision                  0.98\n",
      "Recall                     0.99\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "report = {\n",
    "    'Model': ['Logistic Regression', 'Decision Tree', 'Random Forest','HistGradientBoosting', 'XGBoost'],\n",
    "    'Accuracy':[0.61,0.95,0.98,0.89,0.86],\n",
    "    'Macro-F1 Score':[ 0.51, 0.90, 0.98, 0.89,0.86],\n",
    "    'Precision': [0.63,0.92,0.98,0.91,0.89],\n",
    "    'Recall': [0.49 ,0.90 ,0.97 ,0.89,0.84]\n",
    "\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(report)\n",
    "\n",
    "# Print comparison table\n",
    "print(\"Comparison Table:\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Find the best model based on Macro-F1 Score\n",
    "best_model = df.loc[df['Macro-F1 Score'].idxmax()]\n",
    "\n",
    "# Print the best model\n",
    "print(\"\\nBest Model Based on Macro-F1 Score:\")\n",
    "print(best_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\ma\\core.py:2881: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 25}\n",
      "\n",
      "Classification Report on Test Data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89   1752940\n",
      "           1       0.84      0.82      0.83    902698\n",
      "           2       0.94      0.86      0.90   1492354\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.88   4147992\n",
      "   macro avg       0.66      0.65      0.65   4147992\n",
      "weighted avg       0.88      0.88      0.88   4147992\n",
      "\n",
      "\n",
      "Confusion Matrix on Test Data:\n",
      "[[1624035   86829   40203    1873]\n",
      " [ 115857  737620   48063    1158]\n",
      " [ 158034   49267 1284151     902]\n",
      " [      0       0       0       0]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from joblib import dump\n",
    "\n",
    "# Load training data\n",
    "train_data_path = r\"C:\\Projects\\Microsoft-project\\Final_Train_DS.csv\"\n",
    "train_df = pd.read_csv(train_data_path)\n",
    "\n",
    "# Downcast numerical columns in training data\n",
    "for col in train_df.columns:\n",
    "    if train_df[col].dtype == 'float64':\n",
    "        train_df[col] = pd.to_numeric(train_df[col], downcast='float')\n",
    "    elif train_df[col].dtype == 'int64':\n",
    "        train_df[col] = pd.to_numeric(train_df[col], downcast='integer')\n",
    "\n",
    "# Sample a subset of training data for hyperparameter tuning\n",
    "train_df_subset = train_df.sample(n=500000, random_state=42)\n",
    "X_train_subset = train_df_subset.drop('IncidentGrade', axis=1)\n",
    "y_train_subset = train_df_subset['IncidentGrade']\n",
    "\n",
    "# Initialize RandomForestClassifier with balanced class weight\n",
    "rf = RandomForestClassifier(class_weight=\"balanced\", random_state=42)\n",
    "\n",
    "# Define a limited set of hyperparameters\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10,15, 20,25],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'min_samples_leaf': [2, 4],\n",
    "    'max_features': ['sqrt','log2']\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,  # Fewer iterations\n",
    "    scoring='f1_macro',\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model using a subset of data\n",
    "random_search.fit(X_train_subset, y_train_subset)\n",
    "\n",
    "# Retrieve the best model\n",
    "best_rf = random_search.best_estimator_\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Save the optimized model\n",
    "model_save_path = r\"C:\\Projects\\Microsoft-project\\optimized_random_forest_model.pkl\"\n",
    "dump(best_rf, model_save_path)\n",
    "\n",
    "# Load and preprocess test data\n",
    "test_data_path = r\"C:\\Projects\\Microsoft-project\\Final_Test_DS.csv\"\n",
    "test_df = pd.read_csv(test_data_path)\n",
    "X_test = test_df.drop(['IncidentGrade', 'Usage'], axis=1)  \n",
    "y_test = test_df['IncidentGrade']\n",
    "\n",
    "# Predict on test set and evaluate\n",
    "y_test_pred = best_rf.predict(X_test)\n",
    "print(\"\\nClassification Report on Test Data:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"\\nConfusion Matrix on Test Data:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:370: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:861: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_estimators': 150, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 15}\n",
      "\n",
      "Accuracy on Test Data: 0.8084\n",
      "\n",
      "Classification Report on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.78      0.86      0.82   1752940\n",
      "     Class 1       0.73      0.76      0.75    902698\n",
      "     Class 2       0.94      0.77      0.85   1492354\n",
      "\n",
      "   micro avg       0.82      0.81      0.81   4147992\n",
      "   macro avg       0.82      0.80      0.80   4147992\n",
      "weighted avg       0.83      0.81      0.81   4147992\n",
      "\n",
      "\n",
      "Confusion Matrix on Test Data:\n",
      "[[1515014  171680   45954]\n",
      " [ 171629  689309   29466]\n",
      " [ 249877   85926 1148899]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
    "from joblib import dump\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load and preprocess training data\n",
    "train_data_path = r\"C:\\Projects\\Microsoft-project\\Final_Train_DS.csv\"\n",
    "train_df = pd.read_csv(train_data_path)\n",
    "\n",
    "# Downcast numerical columns in training data\n",
    "for col in train_df.columns:\n",
    "    if train_df[col].dtype == 'float64':\n",
    "        train_df[col] = pd.to_numeric(train_df[col], downcast='float')\n",
    "    elif train_df[col].dtype == 'int64':\n",
    "        train_df[col] = pd.to_numeric(train_df[col], downcast='integer')\n",
    "\n",
    "# Sample a smaller subset of training data for hyperparameter tuning\n",
    "train_df_subset = train_df.sample(n=100000, random_state=42)  # Reduced sample size for SMOTE and tuning\n",
    "X_train_subset = train_df_subset.drop('IncidentGrade', axis=1)\n",
    "y_train_subset = train_df_subset['IncidentGrade']\n",
    "\n",
    "# Handle class imbalance using SMOTE with parallel processing\n",
    "smote = SMOTE(random_state=42, n_jobs=-1)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_subset, y_train_subset)\n",
    "\n",
    "# Initialize RandomForestClassifier with balanced class weight and warm start\n",
    "rf = RandomForestClassifier(class_weight=\"balanced\", random_state=42, warm_start=True)\n",
    "\n",
    "# Define a narrower set of hyperparameters for faster tuning\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 150],       # Limited options to speed up tuning\n",
    "    'max_depth': [10, 15],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'min_samples_leaf': [2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV with optimized settings\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,                        # Reduced iterations\n",
    "    scoring='f1_macro',\n",
    "    cv=5,                             # Fewer cross-validation folds\n",
    "    verbose=1,                        # Lower verbosity\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model using the resampled data\n",
    "random_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Retrieve the best model\n",
    "best_rf = random_search.best_estimator_\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Save the optimized model\n",
    "model_save_path = r\"C:\\Projects\\Microsoft-project\\Adv_random_forest_model.pkl\"\n",
    "dump(best_rf, model_save_path)\n",
    "\n",
    "# Load and preprocess test data\n",
    "test_data_path = r\"C:\\Projects\\Microsoft-project\\Final_Test_DS.csv\"\n",
    "test_df = pd.read_csv(test_data_path)\n",
    "X_test = test_df.drop(['IncidentGrade', 'Usage'], axis=1)  \n",
    "y_test = test_df['IncidentGrade']\n",
    "\n",
    "# Predict on test set and evaluate\n",
    "y_test_pred = best_rf.predict(X_test)\n",
    "# Accuracy Score\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"\\nAccuracy on Test Data: {accuracy:.4f}\")\n",
    "\n",
    "# Updated classification report and confusion matrix\n",
    "print(\"\\nClassification Report on Test Data:\")\n",
    "print(classification_report(y_test, y_test_pred, labels=[0, 1, 2], target_names=['Class 0', 'Class 1', 'Class 2'], zero_division=0))\n",
    "\n",
    "print(\"\\nConfusion Matrix on Test Data:\")\n",
    "print(confusion_matrix(y_test, y_test_pred, labels=[0, 1, 2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
